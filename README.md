

```markdown
# âœˆï¸ EPWA Daily Flights ETL Pipeline

This project is an ETL pipeline that extracts, transforms, and loads data about flights related to the **Warsaw Chopin Airport (EPWA)** using the [Aviationstack API](https://aviationstack.com/). It stores and analyzes both detailed and aggregated flight traffic using **PySpark**, **DuckDB**, and **Apache Airflow**.

---

## ğŸ“ Project Structure

```
project_epwa_daily_traffic/
â”œâ”€â”€ airflow/            # Airflow DAGs and config
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/            # Raw JSONs from API
â”‚   â””â”€â”€ processed/      
â”‚       â”œâ”€â”€ daily_traffic/         # Aggregated CSV files (by hour)
â”‚       â””â”€â”€ detailed_flights/      # Detailed flattened data
â”œâ”€â”€ db/
â”‚   â””â”€â”€ epwa_traffic.duckdb        # DuckDB local database
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ extract.py                 # Downloads latest data from API
â”‚   â”œâ”€â”€ transform_daily_traffic.py      # Aggregates traffic by hour
â”‚   â”œâ”€â”€ transform_detailed_scheduled_date.py # Flattens detailed flight data
â”‚   â”œâ”€â”€ load_epwa_daily_traffic.py         # Loads hourly data into DuckDB
â”‚   â””â”€â”€ load_epwa_detailed_flights.py      # Loads detailed data into DuckDB
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Tools Used

- **Python 3.10**
- **PySpark** â€“ transformation and aggregation
- **DuckDB** â€“ fast local analytical database
- **Apache Airflow** â€“ task orchestration
- **Aviationstack API** â€“ flight data source

---

## ğŸš€ Features

- âœ… Extracts live departure and arrival data from EPWA
- âœ… Aggregates traffic counts by hour and operation type
- âœ… Extracts full flight metadata (gate, delay, terminal, etc.)
- âœ… Loads data into DuckDB with support for deduplication and updates
- âœ… Airflow DAG handles end-to-end orchestration

---

## ğŸ” API Key

To use this project, obtain an API key from [https://aviationstack.com/](https://aviationstack.com/) and insert it into `etl/extract.py`.

---

## ğŸ“¦ Local Execution

1. Set up Python environment and install dependencies:
   ```bash
   python -m venv venv
   source venv/bin/activate
   pip install -r requirements.txt
   ```

2. Run ETL manually:
   ```bash
   python etl/extract.py
   python etl/transform_daily_traffic.py
   python etl/load_epwa_daily_traffic.py
   ```

---

## ğŸ§ª Airflow DAG

The Airflow DAG `epwa_flights_pipeline` runs daily and orchestrates the following tasks:

- `extract_from_api`
- `transform_daily_traffic`
- `transform_detailed_flights`
- `load_daily_traffic`
- `load_detailed_flights`

To run Airflow:
```bash
airflow db init
airflow scheduler
airflow webserver
```

---
