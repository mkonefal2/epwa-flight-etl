# âœˆï¸ EPWA Daily Flights ETL Pipeline

This project is an ETL pipeline that extracts, transforms, and loads data about flights related to the **Warsaw Chopin Airport (EPWA)** using the [Aviationstack API](https://aviationstack.com/). It stores and analyzes both detailed and aggregated flight traffic using **PySpark**, **DuckDB**, and **Apache Airflow**.

---

## ğŸ“¦ Quick Start (Automated Setup)

You can set up the entire environment automatically on a fresh Ubuntu machine.

### ğŸ”§ Installation Steps

1. Clone this repository (the installer script is included):
   ```bash
   git clone https://github.com/mkonefal2/epwa-flight-etl.git
   cd epwa-flight-etl
   ```

2. Run the installer (requires sudo):
   ```bash
   chmod +x install_and_start.sh
   sudo ./install_and_start.sh
   ```

3. After the script finishes, open:
   ```
   http://<your-vm-ip>:8080
   ```

   Default Airflow credentials:
   - **Username:** `admin`
   - **Password:** `StrongPassword123`

---

## ğŸ“ Project Structure

```
epwa-flight-etl/
â”œâ”€â”€ airflow/                      # Airflow DAGs and configuration
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                      # Raw JSONs from Aviationstack API
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ daily_traffic/       # Aggregated CSVs by hour
â”‚       â””â”€â”€ detailed_flights/    # Flattened detailed data
â”œâ”€â”€ db/
â”‚   â””â”€â”€ epwa_traffic.duckdb      # DuckDB database
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ extract.py
â”‚   â”œâ”€â”€ transform_daily_traffic.py
â”‚   â”œâ”€â”€ transform_detailed_scheduled_date.py
â”‚   â”œâ”€â”€ load_epwa_daily_traffic.py
â”‚   â””â”€â”€ load_epwa_detailed_flights.py
â””â”€â”€ requirements.txt
```

---

## ğŸ› ï¸ Tools Used

- **Python 3.10**
- **PySpark** â€“ data processing and aggregation
- **DuckDB** â€“ analytical database
- **Apache Airflow** â€“ orchestration of DAGs
- **Aviationstack API** â€“ source of flight data

---

## ğŸ” API Key

Register at [https://aviationstack.com/](https://aviationstack.com/) to get your API key.  
Replace the placeholder in `etl/extract.py` with your key.

---

## ğŸ“š Manual Execution

```bash
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt

python etl/extract.py
python etl/transform_daily_traffic.py
python etl/load_epwa_daily_traffic.py
```

---

## ğŸ§ª Airflow DAG

The DAG `epwa_flights_pipeline` runs daily and contains these tasks:

- `extract_from_api`
- `transform_daily_traffic`
- `transform_detailed_flights`
- `load_daily_traffic`
- `load_detailed_flights`

To run manually:
```bash
airflow db init
airflow scheduler
airflow webserver
```


---

## \ud83d\udc04 Updating the Project

Use the `update_project.sh` script to keep your local repository in sync with GitHub. The script checks for new commits on the tracked remote branch and pulls them if available.

```bash
./update_project.sh
```

You can add this script to a cron job or run it manually whenever you want to ensure you have the latest version.

---

## ğŸ“„ License

This project is licensed under the MIT License.

